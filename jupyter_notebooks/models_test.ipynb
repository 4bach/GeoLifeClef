{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset and building vectors for machine learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns=10\n",
    "# random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining utilities functions to work with the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_environmental_data(df, patches_dir, mean_window_size=None):\n",
    "\n",
    "    \"\"\"This function builds a dataset containing all the latitude,\n",
    "       longitude, and vectors of the environmental tensors associated saved\n",
    "       in a directory.\n",
    "       Used to fit to Scikit-Learn models.\n",
    "       If the environmental tensors are just row vectors (i.e the env. variables\n",
    "       values at the location) then it loads them in a new dataframe.\n",
    "       Otherwise, the tensors are flattened as long row vectors;\n",
    "       that's when the tensors are the env. variables values around the location.\n",
    "\n",
    "       :param df: the locations dataframe, containing (Latitude,Longitude)\n",
    "           columns\n",
    "       :param patches_dir: the directory where the env. patches are saved\n",
    "       :param mean_window_size: if not None, takes the mean value of each\n",
    "       raster on the provided window size\n",
    "       :return: a new dataframe containing the locations concatenated with\n",
    "           their env. vectors\n",
    "    \"\"\"\n",
    "    # import the names of the environmental variables\n",
    "    from environmental_raster_glc import raster_metadata\n",
    "\n",
    "    env_array = list()\n",
    "    # number of values per channel, 1 if patches are vector\n",
    "    n_features_per_channel = 1\n",
    "    for idx in range(len(df)):\n",
    "\n",
    "        # get the original index used to write the patches on disk\n",
    "        true_idx = df.index[idx]\n",
    "        # find the name of the file\n",
    "        patch_name = patches_dir + '/' + str(true_idx)+'.npy'\n",
    "        # reads the file\n",
    "        patch = np.load(patch_name)\n",
    "        # build the row vector\n",
    "        lat, lng = df.loc[true_idx,'Longitude'], df.loc[true_idx,'Latitude']\n",
    "\n",
    "        if mean_window_size:\n",
    "            try:\n",
    "                patch = np.array([ ch[ch.shape[0]//2 - mean_window_size//2:\n",
    "                                      ch.shape[0]//2 + mean_window_size//2,\n",
    "                                      ch.shape[1]//2 - mean_window_size//2:\n",
    "                                      ch.shape[1]//2 + mean_window_size//2\n",
    "                                     ].mean() for ch in patch\n",
    "                                 ])\n",
    "                assert(len(patch.shape)==1)\n",
    "            except IndexError:\n",
    "                raise Exception(\"Channels don't have two dimensions!\")\n",
    "        else:\n",
    "            if len(patch.shape) > 1:\n",
    "                n_features_per_channel = patch.shape[0]*patch.shape[1]\n",
    "            elif len(patch.shape) ==2 :\n",
    "                raise Exception(\"Channel of dimension one: should only be a scalar\\\n",
    "                                 or a two dimensional array\")\n",
    "        # flatten to build row vector\n",
    "        env_array.append(np.concatenate(([lat,lng],patch),axis=None))\n",
    "\n",
    "    rasters_names = sorted(raster_metadata.keys())\n",
    "    if n_features_per_channel == 1:\n",
    "        header_env = rasters_names\n",
    "    else:\n",
    "        header_env = []\n",
    "        for name in rasters_names:\n",
    "            header_env.extend([name+f'__{i}' for i in range(n_features_per_channel)])\n",
    "    header = ['Latitude','Longitude'] + header_env\n",
    "    env_df = pd.DataFrame(env_array, columns=header, dtype='float64')\n",
    "    return env_df\n",
    "\n",
    "def get_taxref_names(self, y, taxonomic_names):\n",
    "    \"\"\"Returns the taxonomic names which corresponds to the list of\n",
    "       species ids\n",
    "       :param y: the list of species\n",
    "       :return: the list of taxonomic names\n",
    "    \"\"\"\n",
    "    return [taxonomic_names[taxonomic_names['glc19SpId']==spid]['taxaName'].iloc[0]\n",
    "            for spid in y\n",
    "           ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2499 occurrences in the dataset\n",
      "505 number of species\n",
      "\n",
      "30 entries observed at interfering locations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>glc19SpId</th>\n",
       "      <th>scName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2345</th>\n",
       "      <td>-1.319287</td>\n",
       "      <td>47.178340</td>\n",
       "      <td>30425</td>\n",
       "      <td>Solanum dulcamara L.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>-1.075745</td>\n",
       "      <td>44.978460</td>\n",
       "      <td>31867</td>\n",
       "      <td>Arenaria montana L.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>-1.075745</td>\n",
       "      <td>44.978460</td>\n",
       "      <td>31734</td>\n",
       "      <td>Tuberaria guttata (L.) Fourr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2444</th>\n",
       "      <td>8.803104</td>\n",
       "      <td>41.886303</td>\n",
       "      <td>30683</td>\n",
       "      <td>Nerium oleander L.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>1.462861</td>\n",
       "      <td>43.538340</td>\n",
       "      <td>29989</td>\n",
       "      <td>Acanthus mollis L.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Longitude   Latitude  glc19SpId                         scName\n",
       "2345  -1.319287  47.178340      30425           Solanum dulcamara L.\n",
       "383   -1.075745  44.978460      31867            Arenaria montana L.\n",
       "1200  -1.075745  44.978460      31734  Tuberaria guttata (L.) Fourr.\n",
       "2444   8.803104  41.886303      30683             Nerium oleander L.\n",
       "796    1.462861  43.538340      29989             Acanthus mollis L."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# working on a subset of Pl@ntNet Trusted: 2500 occurrences\n",
    "df = pd.read_csv('example_occurrences.csv',\n",
    "                 sep=';', header='infer', quotechar='\"', low_memory=True)\n",
    "\n",
    "df = df[['Longitude','Latitude','glc19SpId','scName']]\n",
    "df = df.dropna(axis=0, how='all') #drop nan lines\n",
    "df = df.astype({'glc19SpId': 'int64'})\n",
    "\n",
    "# one liner:\n",
    "#df = df[['Longitude','Latitude','glc19SpId','scName']].dropna(axis=0, how='all').astype({'glc19SpId': 'int64'})\n",
    "# target pandas series of the species identifiers (there are 505 labels)\n",
    "target_df = df['glc19SpId']\n",
    "# correspondence table between ids and the species taxonomic names\n",
    "# (Taxref names with year of discoverie)\n",
    "taxonomic_names = pd.read_csv('../data/occurrences/taxaName_glc19SpId.csv',\n",
    "                              sep=';',header='infer', quotechar='\"',low_memory=True)\n",
    "# glc_dataset = GLCDataset(df[['Longitude','Latitude']], df['glc19SpId'],\n",
    "#                          scnames=df[['glc19SpId','scName']],patches_dir='example_envtensors')\n",
    "\n",
    "print(len(df), 'occurrences in the dataset')\n",
    "print(len(target_df.unique()), 'number of species\\n')\n",
    "duplicated_df = df[df.duplicated(subset=['Latitude','Longitude'],keep=False)]\n",
    "print(f'{len(duplicated_df)} entries observed at interfering locations:')\n",
    "display(duplicated_df.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One example of two interfering examples: at index 383 and index 1200: lat,lng =(44.978460,-1.075745) and species ids = 31867 (Arenaria montana L.) and 31734 (Tuberaria guttata (L.) Fourr.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>alti</th>\n",
       "      <th>awc_top</th>\n",
       "      <th>bs_top</th>\n",
       "      <th>...</th>\n",
       "      <th>etp</th>\n",
       "      <th>oc_top</th>\n",
       "      <th>pd_top</th>\n",
       "      <th>proxi_eau_fast</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.118889</td>\n",
       "      <td>43.95195</td>\n",
       "      <td>189.375</td>\n",
       "      <td>165.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1219.375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.592500</td>\n",
       "      <td>45.10639</td>\n",
       "      <td>45.625</td>\n",
       "      <td>120.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1140.625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.534861</td>\n",
       "      <td>48.38958</td>\n",
       "      <td>69.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>...</td>\n",
       "      <td>800.625</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Latitude  Longitude     alti  awc_top  bs_top  ...       etp  oc_top  \\\n",
       "0  2.118889   43.95195  189.375    165.0    85.0  ...  1219.375     1.0   \n",
       "1 -0.592500   45.10639   45.625    120.0    35.0  ...  1140.625     1.0   \n",
       "2 -4.534861   48.38958   69.375      0.0    85.0  ...   800.625     2.0   \n",
       "\n",
       "   pd_top  proxi_eau_fast  text  \n",
       "0     2.0             0.0   2.0  \n",
       "1     1.0             0.0   1.0  \n",
       "2     2.0             0.0   0.0  \n",
       "\n",
       "[3 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    30021\n",
       "1    31997\n",
       "2    31385\n",
       "3    33228\n",
       "4    33228\n",
       "Name: glc19SpId, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env_df = build_environmental_data(df[['Latitude','Longitude']],patches_dir='example_envtensors')\n",
    "assert(len(df) == len(env_df))\n",
    "X = env_df.values\n",
    "y = target_df.values\n",
    "display(env_df.head(3))\n",
    "display(target_df.head(5))\n",
    "# the arrays to train our machine learning models\n",
    "X = env_df.values\n",
    "y = target_df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier class and the Vector model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vector model in the geolocation + environmental space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean\n",
      "  Top30 score:0.2\n",
      "  MRR score:0.05445028194533972\n",
      "Cosine\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3f35e4e83ded>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cosine'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVectorModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cosine'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0my_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mranking_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'  Top30 score:{clf.top30_score(y_predicted, y_test)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'  MRR score:{clf.mrr_score(y_predicted, y_test)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/geolifeclef/GLC19/vector_model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, ranking_size)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0margsort\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_argsorts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0munique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mranking_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0my_predicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/geolifeclef/GLC19/vector_model.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0margsort\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_argsorts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0munique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mranking_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0my_predicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from vector_model import VectorModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state)\n",
    "clf = VectorModel(metric='euclidean')\n",
    "clf.fit(X_train,y_train)\n",
    "print('Euclidean')\n",
    "y_predicted = clf.predict(X_test)\n",
    "print(f'  Top30 score:{clf.top30_score(y_predicted, y_test)}')\n",
    "print(f'  MRR score:{clf.mrr_score(y_predicted, y_test)}')\n",
    "\n",
    "print('Cosine')\n",
    "clf = VectorModel(metric='cosine')\n",
    "clf.fit(X_train,y_train)\n",
    "y_predicted = clf.predict(X_test)\n",
    "print(f'  Top30 score:{clf.top30_score(y_predicted, y_test)}')\n",
    "print(f'  MRR score:{clf.mrr_score(y_predicted, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform weights\n",
      "  Top30 score:0.07\n",
      "  MRR score:0.009346689260969971\n",
      "Inverse to distance weights\n",
      "  Top30 score:0.07\n",
      "  MRR score:0.009346689260969971\n"
     ]
    }
   ],
   "source": [
    "from knn_model import KNearestNeighborsModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "clf = KNearestNeighborsModel(weights='uniform',metric='euclidean')\n",
    "clf.fit(X_train,y_train)\n",
    "print('Uniform weights')\n",
    "y_predicted = clf.predict(X_test, ranking_size=30)\n",
    "print(f'  Top30 score:{clf.top30_score(y_predicted, y_test)}')\n",
    "print(f'  MRR score:{clf.mrr_score(y_predicted, y_test)}')\n",
    "\n",
    "clf = KNearestNeighborsModel(weights='distance',metric='euclidean')\n",
    "clf.fit(X_train,y_train)\n",
    "print('Inverse to distance weights')\n",
    "y_predicted = clf.predict(X_test, ranking_size=30)\n",
    "print(f'  Top30 score:{clf.top30_score(y_predicted, y_test)}')\n",
    "print(f'  MRR score:{clf.mrr_score(y_predicted, y_test)}')\n",
    "# TODO : débugger distance cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The K-nearest-neighbors model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29969 29970 29971 29972 29973 29976 29977 29978 29979 29980 29981 29982\n",
      " 29983 29985 29987 29988 29989 29990 29992 29993 30003 30004 30005 30015\n",
      " 30016 30018 30021 30023 30024 30025 30026 30029 30032 30033 30040 30041\n",
      " 30048 30051 30054 30055 30056 30059 30062 30063 30067 30069 30071 30074\n",
      " 30075 30076 30079 30081 30083 30084 30090 30091 30101 30102 30103 30105\n",
      " 30106 30113 30114 30115 30119 30120 30123 30126 30133 30134 30136 30144\n",
      " 30147 30148 30155 30156 30159 30162 30166 30180 30181 30182 30183 30184\n",
      " 30185 30186 30190 30191 30196 30205 30207 30212 30215 30221 30224 30225\n",
      " 30226 30229 30230 30244 30248 30253 30255 30256 30261 30264 30270 30272\n",
      " 30275 30280 30283 30290 30295 30306 30307 30308 30311 30316 30320 30324\n",
      " 30325 30329 30330 30331 30337 30340 30341 30345 30346 30348 30349 30351\n",
      " 30352 30353 30354 30358 30360 30363 30367 30379 30401 30402 30405 30406\n",
      " 30407 30415 30416 30420 30421 30423 30424 30425 30429 30432 30433 30435\n",
      " 30436 30440 30442 30443 30444 30447 30449 30451 30455 30461 30463 30467\n",
      " 30468 30472 30478 30479 30483 30485 30486 30488 30489 30492 30494 30495\n",
      " 30500 30501 30504 30505 30509 30514 30516 30523 30524 30527 30536 30545\n",
      " 30548 30554 30584 30587 30589 30591 30597 30605 30610 30612 30626 30630\n",
      " 30634 30638 30651 30661 30674 30683 30684 30687 30688 30694 30697 30698\n",
      " 30699 30718 30721 30723 30728 30730 30731 30745 30750 30752 30762 30772\n",
      " 30779 30781 30786 30791 30830 30833 30843 30844 30848 30849 30860 30866\n",
      " 30882 30884 30891 30896 30898 30901 30902 30905 30911 30914 30920 30921\n",
      " 30922 30924 30925 30928 30931 30933 30935 30938 30943 30949 30953 30955\n",
      " 30966 30968 30973 30988 30989 30992 30999 31006 31010 31021 31027 31028\n",
      " 31047 31049 31051 31063 31064 31067 31071 31082 31089 31090 31091 31097\n",
      " 31100 31105 31107 31112 31115 31123 31136 31140 31141 31148 31155 31160\n",
      " 31164 31167 31170 31174 31180 31185 31186 31202 31211 31218 31228 31238\n",
      " 31240 31242 31261 31282 31291 31292 31298 31315 31330 31345 31347 31353\n",
      " 31362 31364 31382 31385 31395 31436 31441 31442 31450 31453 31455 31457\n",
      " 31460 31465 31536 31537 31569 31577 31578 31630 31657 31687 31691 31708\n",
      " 31734 31747 31751 31757 31792 31807 31813 31832 31867 31892 31966 31967\n",
      " 31992 31997 32012 32018 32043 32068 32100 32101 32102 32112 32127 32134\n",
      " 32159 32166 32227 32236 32238 32243 32289 32292 32299 32308 32321 32323\n",
      " 32353 32363 32371 32383 32398 32516 32534 32538 32574 32587 32594 32599\n",
      " 32604 32609 32612 32620 32656 32668 32694 32702 32724 32734 32740 32777\n",
      " 32783 32786 32797 32832 32842 32850 32879 32885 32908 32920 32925 32926\n",
      " 32927 32993 33013 33024 33027 33042 33097 33143 33147 33191 33194 33202\n",
      " 33203 33210 33228 33251 33254 33257 33336 33357 33386 33392 33398 33442\n",
      " 33502 33508 33514 33540 33563 33590 33644 33660 33671 33675 33700 33725\n",
      " 33757 33775 33780 33830 33900 33918 33931 33975 34024 34101 34102 34106\n",
      " 34112 34176 34181 34187 34200 34203 34229 34244 34284 34321 34332]\n"
     ]
    }
   ],
   "source": [
    "print(clf.knn_clf.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
